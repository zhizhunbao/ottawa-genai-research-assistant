"""
Rate Limiter

速率限制，保护 API 配额。
"""

import time
from typing import Optional
from collections import defaultdict
from dataclasses import dataclass

from fastapi import HTTPException, Request, status


@dataclass
class RateLimitConfig:
    """速率限制配置"""
    requests: int      # 请求数
    window: int        # 时间窗口（秒）


class RateLimiter:
    """速率限制器（内存实现）"""

    def __init__(self):
        self._requests: dict[str, list[float]] = defaultdict(list)

    def is_allowed(self, key: str, config: RateLimitConfig) -> bool:
        """检查是否允许请求"""
        now = time.time()
        window_start = now - config.window

        # 清理过期记录
        self._requests[key] = [
            t for t in self._requests[key] if t > window_start
        ]

        if len(self._requests[key]) >= config.requests:
            return False

        self._requests[key].append(now)
        return True

    def get_retry_after(self, key: str, config: RateLimitConfig) -> int:
        """获取重试等待时间"""
        if not self._requests[key]:
            return 0
        oldest = min(self._requests[key])
        return max(0, int(config.window - (time.time() - oldest)))


# 默认配置
DEFAULT_LIMITS = {
    "openai": RateLimitConfig(requests=60, window=60),   # 60/min
    "search": RateLimitConfig(requests=100, window=60),  # 100/min
    "upload": RateLimitConfig(requests=10, window=60),   # 10/min
}

_limiter = RateLimiter()


async def check_rate_limit(
    key: str,
    config: Optional[RateLimitConfig] = None,
) -> None:
    """检查速率限制，超限抛出异常"""
    config = config or DEFAULT_LIMITS.get(key, RateLimitConfig(100, 60))

    if not _limiter.is_allowed(key, config):
        retry_after = _limiter.get_retry_after(key, config)
        raise HTTPException(
            status_code=status.HTTP_429_TOO_MANY_REQUESTS,
            detail=f"Rate limit exceeded. Retry after {retry_after}s",
            headers={"Retry-After": str(retry_after)},
        )


# ============================================
# Dependency Usage
# ============================================

# async def rate_limit_openai():
#     await check_rate_limit("openai")
#
# @router.post("/chat")
# async def chat(_: None = Depends(rate_limit_openai)):
#     ...
