"""
Workflow Engine - DAG-based task orchestration with conditional branching.

@module orchestration/workflow/workflow-engine
@source dify/api/core/workflow/workflow_engine.py (execution engine core)
@source dify/api/core/workflow/nodes/ (node type definitions)
@reference https://github.com/langgenius/dify
@template S4-M4-F1

Graph-based workflow execution engine:
1. Define workflows as a DAG of typed nodes
2. Each node has inputs, outputs, and execution logic
3. Edges define data flow and conditional branching
4. Engine traverses the DAG, executing nodes in topological order
5. Supports parallel execution of independent branches
6. Built-in nodes: Start, LLM, Code, Condition, HTTP, End

Pattern: inspired by Dify's visual workflow system,
simplified to ~200 lines of core engine logic.
"""

from __future__ import annotations

import asyncio
import logging
import time
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Callable

logger = logging.getLogger(__name__)


# ─── Enums ───────────────────────────────────────────────────────────────────

class NodeType(str, Enum):
    """Built-in node types."""
    START = "start"
    END = "end"
    LLM = "llm"
    CODE = "code"
    CONDITION = "condition"
    HTTP_REQUEST = "http_request"
    TOOL = "tool"
    VARIABLE_ASSIGN = "variable_assign"
    TEMPLATE = "template"
    PARALLEL = "parallel"


class NodeStatus(str, Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"


class WorkflowStatus(str, Enum):
    IDLE = "idle"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


# ─── Data Models ─────────────────────────────────────────────────────────────

@dataclass
class Edge:
    """Connection between two nodes, optionally with a condition."""
    source_id: str
    target_id: str
    condition: str | None = None  # Expression for conditional branching
    label: str = ""  # "true" / "false" / "default" for condition nodes


@dataclass
class NodeConfig:
    """Configuration for a workflow node."""
    id: str
    type: NodeType
    title: str = ""
    params: dict[str, Any] = field(default_factory=dict)
    position: dict[str, float] = field(default_factory=dict)  # UI position


@dataclass
class NodeResult:
    """Result from executing a single node."""
    node_id: str
    status: NodeStatus
    outputs: dict[str, Any] = field(default_factory=dict)
    error: str | None = None
    elapsed_ms: float = 0.0


@dataclass
class WorkflowDefinition:
    """Complete workflow definition."""
    id: str
    name: str
    nodes: list[NodeConfig] = field(default_factory=list)
    edges: list[Edge] = field(default_factory=list)
    variables: dict[str, Any] = field(default_factory=dict)


@dataclass
class WorkflowRun:
    """State of a workflow execution."""
    workflow_id: str
    status: WorkflowStatus = WorkflowStatus.IDLE
    inputs: dict[str, Any] = field(default_factory=dict)
    outputs: dict[str, Any] = field(default_factory=dict)
    node_results: dict[str, NodeResult] = field(default_factory=dict)
    error: str | None = None
    started_at: float = 0.0
    finished_at: float = 0.0


# ─── Node Executor Interface ────────────────────────────────────────────────
# @source dify/api/core/workflow/nodes/base_node.py

class NodeExecutor(ABC):
    """Abstract base for node execution logic."""
    
    @abstractmethod
    async def execute(
        self,
        node: NodeConfig,
        inputs: dict[str, Any],
        context: dict[str, Any],
    ) -> NodeResult:
        """Execute a single node and return its result."""
        ...


# ─── Built-in Node Executors ────────────────────────────────────────────────

class StartNodeExecutor(NodeExecutor):
    """Passes through workflow inputs."""
    
    async def execute(self, node, inputs, context):
        return NodeResult(
            node_id=node.id,
            status=NodeStatus.COMPLETED,
            outputs=inputs,
        )


class EndNodeExecutor(NodeExecutor):
    """Collects final outputs."""
    
    async def execute(self, node, inputs, context):
        return NodeResult(
            node_id=node.id,
            status=NodeStatus.COMPLETED,
            outputs=inputs,
        )


class ConditionNodeExecutor(NodeExecutor):
    """
    Evaluates a condition expression and outputs the branch to follow.
    @source dify/api/core/workflow/nodes/if_else/
    """
    
    async def execute(self, node, inputs, context):
        expression = node.params.get("expression", "")
        try:
            # Simple eval with restricted namespace
            result = eval(expression, {"__builtins__": {}}, {**inputs, **context})
            return NodeResult(
                node_id=node.id,
                status=NodeStatus.COMPLETED,
                outputs={"result": bool(result), "branch": "true" if result else "false"},
            )
        except Exception as e:
            return NodeResult(
                node_id=node.id,
                status=NodeStatus.FAILED,
                error=str(e),
            )


class CodeNodeExecutor(NodeExecutor):
    """
    Executes a Python code snippet.
    @source dify/api/core/workflow/nodes/code/
    """
    
    async def execute(self, node, inputs, context):
        code = node.params.get("code", "")
        try:
            local_vars: dict[str, Any] = {"inputs": inputs, "context": context}
            exec(code, {"__builtins__": {"str": str, "int": int, "float": float, 
                                          "list": list, "dict": dict, "len": len,
                                          "range": range, "print": print}}, local_vars)
            outputs = local_vars.get("outputs", {})
            return NodeResult(
                node_id=node.id,
                status=NodeStatus.COMPLETED,
                outputs=outputs if isinstance(outputs, dict) else {"result": outputs},
            )
        except Exception as e:
            return NodeResult(
                node_id=node.id,
                status=NodeStatus.FAILED,
                error=str(e),
            )


class TemplateNodeExecutor(NodeExecutor):
    """Renders a template string with variable substitution."""
    
    async def execute(self, node, inputs, context):
        template = node.params.get("template", "")
        try:
            result = template.format(**{**context, **inputs})
            return NodeResult(
                node_id=node.id,
                status=NodeStatus.COMPLETED,
                outputs={"text": result},
            )
        except Exception as e:
            return NodeResult(
                node_id=node.id,
                status=NodeStatus.FAILED,
                error=str(e),
            )


# ─── Workflow Engine ─────────────────────────────────────────────────────────
# @source dify/api/core/workflow/workflow_engine.py

class WorkflowEngine:
    """
    DAG-based workflow execution engine.
    
    Traverses the workflow graph in topological order,
    executing each node and passing outputs to connected nodes.
    """
    
    def __init__(self):
        self._executors: dict[NodeType, NodeExecutor] = {
            NodeType.START: StartNodeExecutor(),
            NodeType.END: EndNodeExecutor(),
            NodeType.CONDITION: ConditionNodeExecutor(),
            NodeType.CODE: CodeNodeExecutor(),
            NodeType.TEMPLATE: TemplateNodeExecutor(),
        }
        self._on_node_start: Callable | None = None
        self._on_node_complete: Callable | None = None
    
    def register_executor(self, node_type: NodeType, executor: NodeExecutor):
        """Register a custom node executor."""
        self._executors[node_type] = executor
    
    def on_node_start(self, callback: Callable[[str, NodeConfig], None]):
        """Set callback for node start events."""
        self._on_node_start = callback
    
    def on_node_complete(self, callback: Callable[[str, NodeResult], None]):
        """Set callback for node completion events."""
        self._on_node_complete = callback
    
    async def run(
        self,
        workflow: WorkflowDefinition,
        inputs: dict[str, Any] | None = None,
    ) -> WorkflowRun:
        """
        Execute a workflow from start to end.
        """
        run = WorkflowRun(
            workflow_id=workflow.id,
            status=WorkflowStatus.RUNNING,
            inputs=inputs or {},
            started_at=time.time(),
        )
        
        try:
            # Build adjacency graph
            node_map = {n.id: n for n in workflow.nodes}
            edges_from: dict[str, list[Edge]] = {}
            for edge in workflow.edges:
                edges_from.setdefault(edge.source_id, []).append(edge)
            
            # Find start node
            start_nodes = [n for n in workflow.nodes if n.type == NodeType.START]
            if not start_nodes:
                raise ValueError("Workflow has no START node")
            
            # BFS execution through the graph
            context: dict[str, Any] = {**workflow.variables, **(inputs or {})}
            queue = [start_nodes[0].id]
            visited = set()
            
            while queue:
                node_id = queue.pop(0)
                if node_id in visited:
                    continue
                visited.add(node_id)
                
                node = node_map.get(node_id)
                if not node:
                    continue
                
                # Collect inputs from predecessor outputs
                node_inputs = dict(context)
                for edge in workflow.edges:
                    if edge.target_id == node_id:
                        pred_result = run.node_results.get(edge.source_id)
                        if pred_result and pred_result.status == NodeStatus.COMPLETED:
                            node_inputs.update(pred_result.outputs)
                
                # Execute
                executor = self._executors.get(node.type)
                if not executor:
                    result = NodeResult(
                        node_id=node_id,
                        status=NodeStatus.FAILED,
                        error=f"No executor for node type: {node.type}",
                    )
                else:
                    if self._on_node_start:
                        self._on_node_start(run.workflow_id, node)
                    
                    start = time.time()
                    result = await executor.execute(node, node_inputs, context)
                    result.elapsed_ms = (time.time() - start) * 1000
                    
                    if self._on_node_complete:
                        self._on_node_complete(run.workflow_id, result)
                
                run.node_results[node_id] = result
                
                # Update context with outputs
                if result.status == NodeStatus.COMPLETED:
                    context.update(result.outputs)
                
                # Determine next nodes
                if result.status == NodeStatus.FAILED:
                    run.status = WorkflowStatus.FAILED
                    run.error = f"Node {node.title or node_id} failed: {result.error}"
                    break
                
                outgoing = edges_from.get(node_id, [])
                for edge in outgoing:
                    if node.type == NodeType.CONDITION:
                        # Only follow matching branch
                        branch = result.outputs.get("branch", "true")
                        if edge.label == branch or edge.label == "default":
                            queue.append(edge.target_id)
                    else:
                        queue.append(edge.target_id)
            
            # Finalize
            if run.status == WorkflowStatus.RUNNING:
                run.status = WorkflowStatus.COMPLETED
                # Collect outputs from END nodes
                for node in workflow.nodes:
                    if node.type == NodeType.END and node.id in run.node_results:
                        run.outputs.update(run.node_results[node.id].outputs)
        
        except Exception as e:
            run.status = WorkflowStatus.FAILED
            run.error = str(e)
            logger.exception(f"Workflow {workflow.id} failed")
        
        run.finished_at = time.time()
        return run
