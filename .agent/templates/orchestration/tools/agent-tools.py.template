"""
Agent Tools - Secure code execution, file operations, and web search

@module orchestration/tools/code-executor
@source joyagent-jdgenie/genie-tool/genie_tool/tool/code_interpreter.py (184L)
@source joyagent-jdgenie/genie-tool/genie_tool/tool/search_component/search_engine.py MixSearch (250L)
@source joyagent-jdgenie/genie-tool/genie_tool/tool/deepsearch.py DeepSearch (202L)
@reference https://github.com/jd-opensource/joyagent-jdgenie
@template S4-M1-F1

Three production-grade agent tools:
1. CodeExecutor — Sandboxed Python execution with file I/O and timeout
2. FileManager — File operations (read/write/convert) with extension validation
3. WebSearch — Multi-engine parallel search with deduplication

Key patterns from JDGenie:
- BaseTool protocol with execute() interface
- Temp directory isolation for code execution (shutil.rmtree cleanup)
- Multi-engine search aggregation (Bing + Jina + Serper)
- Query decomposition → parallel search → dedup → answer
- Async generator streaming for DeepSearch
"""

from __future__ import annotations

import asyncio
import logging
import os
import re
import shutil
import subprocess
import tempfile
import time
from abc import ABC, abstractmethod
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Any, AsyncGenerator, Callable, Optional

logger = logging.getLogger(__name__)


# ─── Base Tool Protocol ──────────────────────────────────────────────────────

class ToolStatus(str, Enum):
    """Status of a tool execution."""
    SUCCESS = "success"
    ERROR = "error"
    TIMEOUT = "timeout"
    CANCELLED = "cancelled"


@dataclass
class ToolResult:
    """Result from a tool execution."""
    status: ToolStatus
    output: str = ""
    error: str = ""
    files: list[dict[str, Any]] = field(default_factory=list)
    metadata: dict[str, Any] = field(default_factory=dict)
    execution_time_ms: int = 0


class BaseTool(ABC):
    """
    Abstract base class for agent tools.

    All tools follow a consistent interface:
    - name: Human-readable tool name
    - description: What the tool does (for LLM function calling)
    - execute(): Run the tool with given parameters
    """

    @property
    @abstractmethod
    def name(self) -> str:
        ...

    @property
    @abstractmethod
    def description(self) -> str:
        ...

    @abstractmethod
    async def execute(self, **kwargs: Any) -> ToolResult:
        """Execute the tool with given parameters."""
        ...

    def to_schema(self) -> dict[str, Any]:
        """Export tool schema for LLM function calling."""
        return {
            "type": "function",
            "function": {
                "name": self.name,
                "description": self.description,
                "parameters": self._get_parameters_schema(),
            },
        }

    def _get_parameters_schema(self) -> dict[str, Any]:
        """Override to provide parameter JSON schema."""
        return {"type": "object", "properties": {}, "required": []}


# ─── Code Executor ────────────────────────────────────────────────────────────
# @source joyagent-jdgenie code_interpreter.py code_interpreter_agent (27-136L)

class CodeExecutor(BaseTool):
    """
    Sandboxed Python code execution tool.

    @source joyagent-jdgenie/genie-tool/genie_tool/tool/code_interpreter.py

    Key features:
    - Temp directory isolation (auto-cleanup)
    - Subprocess execution with timeout
    - Restricted imports (configurable allowlist)
    - Output file capture
    - stdout/stderr capture

    Usage:
        executor = CodeExecutor(timeout=30)
        result = await executor.execute(
            code="import pandas as pd; print(pd.DataFrame({'a': [1,2,3]}))",
        )
    """

    def __init__(
        self,
        timeout: int = 30,
        max_output_size: int = 10000,
        allowed_imports: list[str] | None = None,
    ):
        self.timeout = timeout
        self.max_output_size = max_output_size
        self.allowed_imports = allowed_imports or [
            "pandas", "numpy", "matplotlib", "seaborn",
            "json", "csv", "math", "os", "re", "datetime",
            "collections", "itertools", "functools",
        ]

    @property
    def name(self) -> str:
        return "code_executor"

    @property
    def description(self) -> str:
        return (
            "Execute Python code in a sandboxed environment. "
            "Can read/write files, process data, and generate outputs."
        )

    def _get_parameters_schema(self) -> dict[str, Any]:
        return {
            "type": "object",
            "properties": {
                "code": {
                    "type": "string",
                    "description": "Python code to execute",
                },
                "input_files": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "Paths to input files to make available",
                },
            },
            "required": ["code"],
        }

    async def execute(self, **kwargs: Any) -> ToolResult:
        """Execute Python code in a sandboxed subprocess."""
        code: str = kwargs.get("code", "")
        input_files: list[str] = kwargs.get("input_files", [])

        if not code.strip():
            return ToolResult(status=ToolStatus.ERROR, error="No code provided")

        # Validate imports
        violation = self._check_imports(code)
        if violation:
            return ToolResult(
                status=ToolStatus.ERROR,
                error=f"Forbidden import: {violation}",
            )

        work_dir = tempfile.mkdtemp(prefix="agent_code_")
        start_time = time.monotonic()

        try:
            # Copy input files to work directory
            for file_path in input_files:
                src = Path(file_path)
                if src.exists():
                    shutil.copy2(src, Path(work_dir) / src.name)

            # Write code to temp file
            script_path = Path(work_dir) / "script.py"
            script_path.write_text(code, encoding="utf-8")

            # Execute in subprocess
            result = await asyncio.to_thread(
                self._run_subprocess, str(script_path), work_dir
            )

            elapsed = int((time.monotonic() - start_time) * 1000)
            result.execution_time_ms = elapsed

            # Capture output files
            output_dir = Path(work_dir)
            output_files = [
                {"name": f.name, "path": str(f), "size": f.stat().st_size}
                for f in output_dir.iterdir()
                if f.is_file() and f.name != "script.py"
            ]
            result.files = output_files

            return result

        except Exception as e:
            elapsed = int((time.monotonic() - start_time) * 1000)
            return ToolResult(
                status=ToolStatus.ERROR,
                error=str(e),
                execution_time_ms=elapsed,
            )
        finally:
            # Cleanup: remove work directory
            shutil.rmtree(work_dir, ignore_errors=True)

    def _run_subprocess(self, script_path: str, work_dir: str) -> ToolResult:
        """Run Python script in subprocess with timeout."""
        try:
            result = subprocess.run(
                ["python", script_path],
                capture_output=True,
                text=True,
                timeout=self.timeout,
                cwd=work_dir,
            )

            stdout = result.stdout[:self.max_output_size]
            stderr = result.stderr[:self.max_output_size]

            if result.returncode == 0:
                return ToolResult(
                    status=ToolStatus.SUCCESS,
                    output=stdout,
                    error=stderr if stderr else "",
                )
            else:
                return ToolResult(
                    status=ToolStatus.ERROR,
                    output=stdout,
                    error=stderr or f"Exit code: {result.returncode}",
                )

        except subprocess.TimeoutExpired:
            return ToolResult(
                status=ToolStatus.TIMEOUT,
                error=f"Execution timed out after {self.timeout}s",
            )

    def _check_imports(self, code: str) -> str | None:
        """Check for forbidden imports. Returns the first violation or None."""
        import_pattern = re.compile(r"^(?:from\s+(\S+)|import\s+(\S+))", re.MULTILINE)
        for match in import_pattern.finditer(code):
            module = match.group(1) or match.group(2)
            root_module = module.split(".")[0]
            if root_module not in self.allowed_imports:
                return root_module
        return None


# ─── File Manager ─────────────────────────────────────────────────────────────

class FileManager(BaseTool):
    """
    File operations tool for agents.

    Supports:
    - Read text/binary files
    - Write content to files
    - List directory contents
    - Check file existence and size
    """

    def __init__(
        self,
        base_dir: str = ".",
        max_file_size: int = 10 * 1024 * 1024,  # 10MB
        allowed_extensions: list[str] | None = None,
    ):
        self.base_dir = Path(base_dir).resolve()
        self.max_file_size = max_file_size
        self.allowed_extensions = allowed_extensions or [
            ".txt", ".md", ".py", ".json", ".csv", ".html", ".xml",
            ".yaml", ".yml", ".toml", ".cfg", ".ini", ".log",
        ]

    @property
    def name(self) -> str:
        return "file_manager"

    @property
    def description(self) -> str:
        return "Read, write, and manage files. Can read text files and write content."

    def _get_parameters_schema(self) -> dict[str, Any]:
        return {
            "type": "object",
            "properties": {
                "action": {
                    "type": "string",
                    "enum": ["read", "write", "list", "exists"],
                    "description": "File operation to perform",
                },
                "path": {
                    "type": "string",
                    "description": "File or directory path (relative to base_dir)",
                },
                "content": {
                    "type": "string",
                    "description": "Content to write (for write action)",
                },
            },
            "required": ["action", "path"],
        }

    async def execute(self, **kwargs: Any) -> ToolResult:
        action: str = kwargs.get("action", "read")
        path: str = kwargs.get("path", "")
        content: str = kwargs.get("content", "")

        # Resolve and validate path
        target = (self.base_dir / path).resolve()
        if not str(target).startswith(str(self.base_dir)):
            return ToolResult(
                status=ToolStatus.ERROR,
                error="Path traversal not allowed",
            )

        try:
            if action == "read":
                return await self._read_file(target)
            elif action == "write":
                return await self._write_file(target, content)
            elif action == "list":
                return await self._list_dir(target)
            elif action == "exists":
                exists = target.exists()
                return ToolResult(
                    status=ToolStatus.SUCCESS,
                    output=str(exists),
                    metadata={"exists": exists, "is_file": target.is_file()},
                )
            else:
                return ToolResult(
                    status=ToolStatus.ERROR, error=f"Unknown action: {action}"
                )
        except Exception as e:
            return ToolResult(status=ToolStatus.ERROR, error=str(e))

    async def _read_file(self, path: Path) -> ToolResult:
        if not path.exists():
            return ToolResult(status=ToolStatus.ERROR, error="File not found")
        if path.stat().st_size > self.max_file_size:
            return ToolResult(status=ToolStatus.ERROR, error="File too large")
        content = await asyncio.to_thread(path.read_text, encoding="utf-8")
        return ToolResult(
            status=ToolStatus.SUCCESS,
            output=content,
            metadata={"size": path.stat().st_size},
        )

    async def _write_file(self, path: Path, content: str) -> ToolResult:
        if path.suffix not in self.allowed_extensions:
            return ToolResult(
                status=ToolStatus.ERROR,
                error=f"Extension '{path.suffix}' not allowed",
            )
        path.parent.mkdir(parents=True, exist_ok=True)
        await asyncio.to_thread(path.write_text, content, encoding="utf-8")
        return ToolResult(
            status=ToolStatus.SUCCESS,
            output=f"Written to {path.name}",
            metadata={"size": len(content.encode("utf-8"))},
        )

    async def _list_dir(self, path: Path) -> ToolResult:
        if not path.is_dir():
            return ToolResult(status=ToolStatus.ERROR, error="Not a directory")
        items = sorted(path.iterdir())
        listing = "\n".join(
            f"{'[DIR]' if f.is_dir() else f'{f.stat().st_size:>8}B'} {f.name}"
            for f in items
        )
        return ToolResult(status=ToolStatus.SUCCESS, output=listing)


# ─── Web Search ───────────────────────────────────────────────────────────────
# @source joyagent-jdgenie search_engine.py SearchBase + MixSearch (250L)

@dataclass
class SearchDoc:
    """A search result document."""
    title: str = ""
    url: str = ""
    content: str = ""
    snippet: str = ""
    engine: str = ""

    def to_dict(self, truncate_len: int = 200) -> dict[str, Any]:
        return {
            "title": self.title,
            "url": self.url,
            "content": self.content[:truncate_len] if self.content else "",
            "snippet": self.snippet,
            "engine": self.engine,
        }


class WebSearch(BaseTool):
    """
    Multi-engine web search tool with deduplication.

    @source joyagent-jdgenie/genie-tool/genie_tool/tool/search_component/search_engine.py

    Key patterns from JDGenie:
    - SearchBase ABC with search() method
    - MixSearch aggregates multiple engines
    - Parallel search with ThreadPoolExecutor
    - Content deduplication by URL or text hash
    - BeautifulSoup HTML parsing for content extraction

    Usage:
        search = WebSearch(search_fn=my_search_function)
        result = await search.execute(query="latest AI news", top_k=10)
    """

    def __init__(
        self,
        search_fn: Callable[[str, int], list[SearchDoc]] | None = None,
        max_results: int = 10,
        timeout: int = 10,
        max_workers: int = 3,
    ):
        self._search_fn = search_fn
        self.max_results = max_results
        self.timeout = timeout
        self.max_workers = max_workers

    @property
    def name(self) -> str:
        return "web_search"

    @property
    def description(self) -> str:
        return "Search the web for information. Returns relevant web pages."

    def _get_parameters_schema(self) -> dict[str, Any]:
        return {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "Search query",
                },
                "top_k": {
                    "type": "integer",
                    "description": "Number of results to return",
                    "default": 10,
                },
            },
            "required": ["query"],
        }

    async def execute(self, **kwargs: Any) -> ToolResult:
        query: str = kwargs.get("query", "")
        top_k: int = kwargs.get("top_k", self.max_results)

        if not query.strip():
            return ToolResult(status=ToolStatus.ERROR, error="No query provided")

        if not self._search_fn:
            return ToolResult(
                status=ToolStatus.ERROR,
                error="No search function configured",
            )

        try:
            docs = await asyncio.to_thread(self._search_fn, query, top_k)

            # Deduplicate by URL
            seen_urls: set[str] = set()
            deduped: list[SearchDoc] = []
            for doc in docs:
                if doc.url not in seen_urls:
                    deduped.append(doc)
                    seen_urls.add(doc.url)

            deduped = deduped[:top_k]

            output_parts = []
            for i, doc in enumerate(deduped, 1):
                output_parts.append(
                    f"[{i}] {doc.title}\n    URL: {doc.url}\n    {doc.snippet or doc.content[:200]}"
                )

            return ToolResult(
                status=ToolStatus.SUCCESS,
                output="\n\n".join(output_parts),
                metadata={
                    "result_count": len(deduped),
                    "results": [d.to_dict() for d in deduped],
                },
            )

        except Exception as e:
            return ToolResult(status=ToolStatus.ERROR, error=str(e))


# ─── Tool Registry ───────────────────────────────────────────────────────────

class ToolRegistry:
    """
    Registry for managing available agent tools.

    Usage:
        registry = ToolRegistry()
        registry.register(CodeExecutor())
        registry.register(FileManager())
        registry.register(WebSearch(search_fn=...))

        tool = registry.get("code_executor")
        result = await tool.execute(code="print('hello')")

        # Export schemas for LLM function calling
        schemas = registry.to_schemas()
    """

    def __init__(self) -> None:
        self._tools: dict[str, BaseTool] = {}

    def register(self, tool: BaseTool) -> None:
        """Register a tool."""
        self._tools[tool.name] = tool

    def get(self, name: str) -> BaseTool:
        """Get a tool by name."""
        if name not in self._tools:
            available = ", ".join(self._tools.keys())
            raise ValueError(f"Unknown tool '{name}'. Available: {available}")
        return self._tools[name]

    @property
    def available(self) -> list[str]:
        """List available tool names."""
        return list(self._tools.keys())

    def to_schemas(self) -> list[dict[str, Any]]:
        """Export all tool schemas for LLM function calling."""
        return [tool.to_schema() for tool in self._tools.values()]
